{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup Paths"
   ],
   "metadata": {
    "id": "QUANWN3rpfC9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os"
   ],
   "outputs": [],
   "metadata": {
    "id": "146BB11JpfDA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "CUSTOM_MODEL_NAME = 'pedestrian' \r\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\r\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\r\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\r\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\r\n",
    "LATEST_MODEL_NAME = 'pedestrian_v1'"
   ],
   "outputs": [],
   "metadata": {
    "id": "42hJEdo_pfDB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "paths = {\r\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\r\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\r\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\r\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\r\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\r\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\r\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\r\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \r\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \r\n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \r\n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \r\n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\r\n",
    "    'LATEST_MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'pre-trained-models')\r\n",
    " }"
   ],
   "outputs": [],
   "metadata": {
    "id": "hbPhYVy_pfDB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "files = {\r\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\r\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \r\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "id": "LwhWZMI0pfDC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for path in paths.values():\r\n",
    "    if not os.path.exists(path):\r\n",
    "        if os.name == 'posix':\r\n",
    "            !mkdir -p {path}\r\n",
    "        if os.name == 'nt':\r\n",
    "            !mkdir {path}"
   ],
   "outputs": [],
   "metadata": {
    "id": "HR-TfDGrpfDC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ],
   "metadata": {
    "id": "OLU-rs_ipfDE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install --user tensorflow-gpu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if os.name=='nt':\r\n",
    "    !pip install wget\r\n",
    "    import wget"
   ],
   "outputs": [],
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\r\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ],
   "outputs": [],
   "metadata": {
    "id": "iA1DIq5OpfDE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Install Tensorflow Object Detection \r\n",
    "if os.name=='posix':  \r\n",
    "    !apt-get install protobuf-compiler\r\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \r\n",
    "    \r\n",
    "if os.name=='nt':\r\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\r\n",
    "    wget.download(url)\r\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\r\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\r\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \r\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\r\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ],
   "outputs": [],
   "metadata": {
    "id": "rJjMHbnDs3Tv",
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\r\n",
    "# Verify Installation\r\n",
    "!python {VERIFICATION_SCRIPT}"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chmod(r\"C:\\Users\\liyij\\AppData\\Local\\Temp\\easy_install-to_akisp\\pycocotools-2.0.2\\.eggs\\Cython-0.29.24-py3.8-win-amd64.egg\\Cython\\Compiler\\FlowControl.cp38-win_amd64.pyd\", 0o777)\r\n",
    "!pip install tensorflow --upgrade"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip uninstall protobuf matplotlib -y\r\n",
    "!pip install protobuf matplotlib==3.2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import object_detection"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip list"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if os.name =='posix':\r\n",
    "    !wget {PRETRAINED_MODEL_URL}\r\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\r\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\r\n",
    "if os.name == 'nt':\r\n",
    "    wget.download(PRETRAINED_MODEL_URL)\r\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\r\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create Label Map"
   ],
   "metadata": {
    "id": "M5KJTnkfpfDC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = [{'name':'crossing', 'id':1}, {'name':'waiting', 'id':2}]\r\n",
    "\r\n",
    "with open(files['LABELMAP'], 'w') as f:\r\n",
    "    for label in labels:\r\n",
    "        f.write('item { \\n')\r\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\r\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\r\n",
    "        f.write('}\\n')"
   ],
   "outputs": [],
   "metadata": {
    "id": "p1BVDWo7pfDC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Create TF records"
   ],
   "metadata": {
    "id": "C88zyVELpfDC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\r\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\r\n",
    "if os.path.exists(ARCHIVE_FILES):\r\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\r\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWpb_BVUpfDD",
    "outputId": "56ce2a3f-3933-4ee6-8a9d-d5ec65f7d73c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \r\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ],
   "metadata": {
    "id": "qT4QU7pLpfDE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if os.name =='posix':\r\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], LATEST_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\r\n",
    "if os.name == 'nt':\r\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], LATEST_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ],
   "outputs": [],
   "metadata": {
    "id": "cOjuTFbwpfDF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Update Config For Transfer Learning"
   ],
   "metadata": {
    "id": "Ga8gpNslpfDF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "from object_detection.utils import config_util\r\n",
    "from object_detection.protos import pipeline_pb2\r\n",
    "from google.protobuf import text_format"
   ],
   "outputs": [],
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "c2A0mn4ipfDF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQA13-afpfDF",
    "outputId": "907496a4-a39d-4b13-8c2c-e5978ecb1f10"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\r\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \r\n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \r\n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ],
   "outputs": [],
   "metadata": {
    "id": "9vK5lotDpfDF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\r\n",
    "pipeline_config.train_config.batch_size = 4\r\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], LATEST_MODEL_NAME, 'checkpoint', 'ckpt-0')\r\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\r\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\r\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\r\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\r\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ],
   "outputs": [],
   "metadata": {
    "id": "rP43Ph0JpfDG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \r\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \r\n",
    "    f.write(config_text)   "
   ],
   "outputs": [],
   "metadata": {
    "id": "oJvfgwWqpfDG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Train the model"
   ],
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chmod(r\"C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\Lib\\site-packages\\~ensorflow\\lite\\experimental\\microfrontend\\python\\ops\\_audio_microfrontend_op.so\", 0o777)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ],
   "outputs": [],
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "jMP2XDfQpfDH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(command)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{command}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Evaluate the Model"
   ],
   "metadata": {
    "id": "4_YRZu7npfDH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "80L7-fdPpfDH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.chmod(r\"C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\Lib\\site-packages\\numpy\\~libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\", 0o777)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(command)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{command}"
   ],
   "outputs": [],
   "metadata": {
    "id": "lqTV2jGBpfDH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ],
   "metadata": {
    "id": "orvRk02UpfDI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import os\r\n",
    "import tensorflow as tf\r\n",
    "from object_detection.utils import label_map_util\r\n",
    "from object_detection.utils import visualization_utils as viz_utils\r\n",
    "from object_detection.builders import model_builder\r\n",
    "from object_detection.utils import config_util"
   ],
   "outputs": [],
   "metadata": {
    "id": "8TYk4_oIpfDI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Load pipeline config and build a detection model\r\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\r\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\r\n",
    "\r\n",
    "# Restore checkpoint\r\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\r\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\r\n",
    "\r\n",
    "@tf.function\r\n",
    "def detect_fn(image):\r\n",
    "    image, shapes = detection_model.preprocess(image)\r\n",
    "    prediction_dict = detection_model.predict(image, shapes)\r\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\r\n",
    "    return detections"
   ],
   "outputs": [],
   "metadata": {
    "id": "tDnQg-cYpfDI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Detect from an Image"
   ],
   "metadata": {
    "id": "0EmsmbBZpfDI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import cv2 \r\n",
    "import numpy as np\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\r\n",
    "print(category_index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1: {'id': 1, 'name': 'crossing'}, 2: {'id': 2, 'name': 'waiting'}}\n"
     ]
    }
   ],
   "metadata": {
    "id": "cBDbIhNapfDI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'pedestrian.62da9174-f377-11eb-b96f-34cff6b8e259.jpg')"
   ],
   "outputs": [],
   "metadata": {
    "id": "Lx3crOhOzITB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#from object_counting import test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "img = cv2.imread(IMAGE_PATH)\r\n",
    "image_np = np.array(img)\r\n",
    "\r\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\r\n",
    "detections = detect_fn(input_tensor)\r\n",
    "\r\n",
    "num_detections = int(detections.pop('num_detections'))\r\n",
    "detections = {key: value[0, :num_detections].numpy()\r\n",
    "              for key, value in detections.items()}\r\n",
    "detections['num_detections'] = num_detections\r\n",
    "\r\n",
    "# detection_classes should be ints.\r\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\r\n",
    "\r\n",
    "label_id_offset = 1\r\n",
    "image_np_with_detections = image_np.copy()\r\n",
    "\r\n",
    "boxes = detections['detection_boxes']\r\n",
    "print(boxes.shape)\r\n",
    "# get all boxes from an array\r\n",
    "max_boxes_to_draw = boxes.shape[0]\r\n",
    "# get scores to get a threshold\r\n",
    "scores = detections['detection_scores']\r\n",
    "# this is set as a default but feel free to adjust it to your needs\r\n",
    "min_score_thresh=.6\r\n",
    "# # iterate over all objects found\r\n",
    "coordinates = []\r\n",
    "for i in range(min(max_boxes_to_draw, boxes.shape[0])):\r\n",
    "    if scores[i] > min_score_thresh:\r\n",
    "        class_id = int(detections['detection_classes'][i] + 1)\r\n",
    "        coordinates.append({\r\n",
    "            \"box\": boxes[i],\r\n",
    "            \"class_name\": category_index[class_id][\"name\"],\r\n",
    "            \"score\": scores[i]\r\n",
    "        })\r\n",
    "\r\n",
    "print(coordinates)\r\n",
    "\r\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
    "            image_np_with_detections,\r\n",
    "            detections['detection_boxes'],\r\n",
    "            detections['detection_classes']+label_id_offset,\r\n",
    "            detections['detection_scores'],\r\n",
    "            category_index,\r\n",
    "            use_normalized_coordinates=True,\r\n",
    "            max_boxes_to_draw=10,\r\n",
    "            min_score_thresh=min_score_thresh,\r\n",
    "            agnostic_mode=False)\r\n",
    "            \r\n",
    "cv2.putText(img=image_np_with_detections, text=f'Detected: {len(coordinates)}', org=(7, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=1, lineType=cv2.LINE_AA)\r\n",
    "\r\n",
    "print(image_np_with_detections.shape)\r\n",
    "horizontal_cumulative_counting(image_np_with_detections, detected_objects=coordinates, roi_x=0.6, direction='both', deviation=0.05)\r\n",
    "\r\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 4)\n",
      "[{'box': array([0.29485372, 0.5312026 , 0.51814425, 0.6105102 ], dtype=float32), 'class_name': 'crossing', 'score': 0.99750316}, {'box': array([0.27347448, 0.84083605, 0.5202948 , 0.9108925 ], dtype=float32), 'class_name': 'waiting', 'score': 0.88289875}, {'box': array([0.34454247, 0.01816466, 0.5336615 , 0.07971964], dtype=float32), 'class_name': 'waiting', 'score': 0.8592536}]\n",
      "(192, 262, 3)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'horizontal_cumulative_counting' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4084/2987341470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np_with_detections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mhorizontal_cumulative_counting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np_with_detections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetected_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'both'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeviation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np_with_detections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'horizontal_cumulative_counting' is not defined"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3",
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ],
   "metadata": {
    "id": "IsNAaYAo0WVL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "left_right = {}\r\n",
    "right_left = {}\r\n",
    "cumulative_counting = {'total': 0}\r\n",
    "\r\n",
    "isDetected = {}\r\n",
    "\r\n",
    "# resets variables\r\n",
    "def reset_counting_variables():\r\n",
    "    global left_right, right_left, cumulative_counting, isDetected\r\n",
    "    left_right = {}\r\n",
    "    right_left = {}\r\n",
    "    cumulative_counting = {'total': 0}\r\n",
    "    isDetected = {}\r\n",
    "    \r\n",
    "\r\n",
    "# cumulative object counting mode along y-axis\r\n",
    "def horizontal_cumulative_counting(frame, detected_objects, roi_x=.5, direction='both', deviation=0.01):\r\n",
    "\r\n",
    "    # added the x_centers(x, y) of all detected boxes to a list\r\n",
    "    x_centers = []\r\n",
    "    for i in range(len(detected_objects)):\r\n",
    "        # bounding box is in the format of [y_up, x_left, y_down, x_right]\r\n",
    "        coordinate = detected_objects[i]['box']\r\n",
    "        x_centers.append((coordinate[3] + coordinate[1]) / 2)\r\n",
    "        \r\n",
    "    # detect if x_center of object crosses ROI\r\n",
    "    insideROI = False # any object is inside ROI\r\n",
    "    if direction == 'right_2_left':\r\n",
    "        for i, x_center in enumerate(x_centers):\r\n",
    "            # get y_center of current object, y_center should not change a lot when crossing ROI\r\n",
    "            coordinate = detected_objects[i]['box']\r\n",
    "            y_center = (coordinate[2] + coordinate[0]) / 2\r\n",
    "            y_center = int(y_center * 10)\r\n",
    "\r\n",
    "            # object withn 1-2 deviations right to ROI, register the object for potential crossing\r\n",
    "            if roi_x + deviation < x_center < roi_x + 2 * deviation:\r\n",
    "                # is the object registered, register if not\r\n",
    "                if y_center not in right_left.keys():\r\n",
    "                    right_left.update({y_center: {'x_pos': x_center, 'status': 'pre-crossing'}})\r\n",
    "                else:\r\n",
    "                    if(x_center <= right_left.get(y_center)['x_pos']): # object moves further left but hasn't crossed ROI line\r\n",
    "                        right_left.update({y_center: {'x_pos': x_center, 'status': 'pre-crossing'}})\r\n",
    "                    else: # object moves right, remove it from potential crossing list\r\n",
    "                        right_left.pop(y_center)\r\n",
    "            elif roi_x - deviation < x_center < roi_x + deviation: # object inside ROI, object must be registered\r\n",
    "                if y_center in right_left.keys():\r\n",
    "                    if right_left.get(y_center)['status'] == 'pre-crossing':\r\n",
    "                        right_left.update({y_center: {'x_pos': x_center, 'status': 'crossing'}})\r\n",
    "                    \r\n",
    "                insideROI = True\r\n",
    "            elif roi_x - 2 * deviation < x_center < roi_x - deviation: # object right to ROI, complete crossing\r\n",
    "                if y_center in right_left.keys(): # object is already registered\r\n",
    "                    if right_left.get(y_center)['status'] == 'crossing':\r\n",
    "                        # remove object\r\n",
    "                        right_left.pop(y_center)\r\n",
    "\r\n",
    "                        # update for all objects\r\n",
    "                        cumulative_counting.update({'total': cumulative_counting.get('total') + 1})\r\n",
    "\r\n",
    "                        # update for each object\r\n",
    "                        class_name = detected_objects[i]['class_name']\r\n",
    "                        if class_name not in cumulative_counting.keys():\r\n",
    "                            cumulative_counting.update({class_name: 1})\r\n",
    "                        else:\r\n",
    "                            cumulative_counting.update({class_name: cumulative_counting.get(class_name) + 1})   \r\n",
    "      \r\n",
    "    elif direction == 'left_2_right':\r\n",
    "        pass\r\n",
    "    elif direction == 'both':\r\n",
    "        global isDetected\r\n",
    "        for i, x_center in enumerate(x_centers):\r\n",
    "            # get y_center of current object, y_center should not change a lot when crossing ROI\r\n",
    "            coordinate = detected_objects[i]['box']\r\n",
    "            y_center = (coordinate[2] + coordinate[0]) / 2\r\n",
    "            y_center = int(y_center * 10)\r\n",
    "\r\n",
    "            if roi_x - deviation < x_center < roi_x + deviation:\r\n",
    "                # object detected\r\n",
    "                insideROI = True\r\n",
    "\r\n",
    "                # check for previous ROI state\r\n",
    "                if y_center not in isDetected.keys():\r\n",
    "                    # register object\r\n",
    "                    isDetected.update({y_center: {'x_pos': x_center, 'status': 'insideROI'}})\r\n",
    "\r\n",
    "                    # update for total count\r\n",
    "                    cumulative_counting.update({'total': cumulative_counting.get('total') + 1})\r\n",
    "\r\n",
    "                    # update for specific label\r\n",
    "                    class_name = detected_objects[i]['class_name']\r\n",
    "                    if class_name not in cumulative_counting.keys():\r\n",
    "                        cumulative_counting.update({class_name: 1})\r\n",
    "                    else:\r\n",
    "                        cumulative_counting.update({class_name: cumulative_counting.get(class_name) + 1})\r\n",
    "                else:\r\n",
    "                    #update 'x_pos' to minimize frame-by-frame y_center difference\r\n",
    "                    isDetected.update({y_center: {'x_pos': x_center, 'status': 'stillInsideROI'}})\r\n",
    "\r\n",
    "            elif roi_x - 2 * deviation < x_center < roi_x - deviation or roi_x + deviation < x_center < 2 * deviation:\r\n",
    "                # deregister object if it leaves ROI\r\n",
    "                if y_center in isDetected.keys():\r\n",
    "                    isDetected.pop(y_center)\r\n",
    "            \r\n",
    "\r\n",
    "    # draw ROI line, red for regular, green if object is detected\r\n",
    "    x_ROI = int(frame.shape[1] * roi_x)\r\n",
    "    width = frame.shape[0]\r\n",
    "    \r\n",
    "    cv2.line(frame, (x_ROI, 0), (x_ROI, width), (0, 0, 255) if insideROI is False else (0, 255, 0), 2)\r\n",
    "    cv2.putText(frame, str(cumulative_counting), (7, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=1, lineType=cv2.LINE_AA)\r\n",
    "\r\n",
    "    return frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "VIDEO_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'walking.avi')\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\r\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\r\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\n",
    "\r\n",
    "#save detection video\r\n",
    "size = (width, height)\r\n",
    "result = cv2.VideoWriter('demo.avi', \r\n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),\r\n",
    "                         10, size)\r\n",
    "\r\n",
    "reset_counting_variables()\r\n",
    "\r\n",
    "while cap.isOpened(): \r\n",
    "    ret, frame = cap.read()\r\n",
    "    image_np = np.array(frame)\r\n",
    "    \r\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\r\n",
    "    detections = detect_fn(input_tensor)\r\n",
    "    \r\n",
    "    num_detections = int(detections.pop('num_detections'))\r\n",
    "    detections = {key: value[0, :num_detections].numpy()\r\n",
    "                  for key, value in detections.items()}\r\n",
    "    detections['num_detections'] = num_detections\r\n",
    "\r\n",
    "    # detection_classes should be ints.\r\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\r\n",
    "\r\n",
    "    label_id_offset = 1\r\n",
    "    image_np_with_detections = image_np.copy()\r\n",
    "    \r\n",
    "    # this is set as a default\r\n",
    "    min_score_thresh=.5\r\n",
    "\r\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
    "                image_np_with_detections,\r\n",
    "                detections['detection_boxes'],\r\n",
    "                detections['detection_classes']+label_id_offset,\r\n",
    "                detections['detection_scores'],\r\n",
    "                category_index,\r\n",
    "                use_normalized_coordinates=True,\r\n",
    "                max_boxes_to_draw=10,\r\n",
    "                min_score_thresh=min_score_thresh,\r\n",
    "                agnostic_mode=False)\r\n",
    "    \r\n",
    "    boxes = detections['detection_boxes']\r\n",
    "    # get all boxes from an array\r\n",
    "    max_boxes_to_draw = boxes.shape[0]\r\n",
    "    # get scores to get a threshold\r\n",
    "    scores = detections['detection_scores']\r\n",
    "    # # iterate over all objects found\r\n",
    "    coordinates = []\r\n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\r\n",
    "        if scores[i] > min_score_thresh:\r\n",
    "            class_id = int(detections['detection_classes'][i] + 1)\r\n",
    "            coordinates.append({\r\n",
    "                \"box\": boxes[i],\r\n",
    "                \"class_name\": category_index[class_id][\"name\"],\r\n",
    "                \"score\": scores[i]\r\n",
    "            })\r\n",
    "            \r\n",
    "    cv2.putText(img=image_np_with_detections, text=f'Detected: {len(coordinates)}', org=(7, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=1, lineType=cv2.LINE_AA)\r\n",
    "    \r\n",
    "\r\n",
    "    image_np_with_detections = horizontal_cumulative_counting(image_np_with_detections, detected_objects=coordinates, roi_x=0.7, direction='both', deviation=0.02)\r\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\r\n",
    "    result.write(image_np_with_detections)\r\n",
    "    \r\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q') or not ret:\r\n",
    "        cap.release()\r\n",
    "        cv2.destroyAllWindows()\r\n",
    "        break\r\n",
    "    \r\n",
    "cv2.destoryAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\liyij\\AppData\\Local\\Temp/ipykernel_4084/1545105165.py:11 detect_fn  *\n        image, shapes = detection_model.preprocess(image)\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\meta_architectures\\ssd_meta_arch.py:484 preprocess  *\n        normalized_inputs, self._image_resizer_fn)\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\utils\\shape_utils.py:492 resize_images_and_return_shapes  *\n        outputs = static_or_dynamic_map_fn(\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\utils\\shape_utils.py:246 static_or_dynamic_map_fn  *\n        outputs = [fn(arg) for arg in tf.unstack(elems)]\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\core\\preprocessor.py:3327 resize_image  *\n        new_image = tf.image.resize_images(\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1538 resize_images\n        return _resize_images_common(\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1396 _resize_images_common\n        raise ValueError('\\'images\\' must have either 3 or 4 dimensions.')\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4084/3098632507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mnum_detections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'num_detections'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\liyij\\AppData\\Local\\Temp/ipykernel_4084/1545105165.py:11 detect_fn  *\n        image, shapes = detection_model.preprocess(image)\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\meta_architectures\\ssd_meta_arch.py:484 preprocess  *\n        normalized_inputs, self._image_resizer_fn)\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\utils\\shape_utils.py:492 resize_images_and_return_shapes  *\n        outputs = static_or_dynamic_map_fn(\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\utils\\shape_utils.py:246 static_or_dynamic_map_fn  *\n        outputs = [fn(arg) for arg in tf.unstack(elems)]\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\core\\preprocessor.py:3327 resize_image  *\n        new_image = tf.image.resize_images(\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1538 resize_images\n        return _resize_images_common(\n    C:\\Users\\liyij\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1396 _resize_images_common\n        raise ValueError('\\'images\\' must have either 3 or 4 dimensions.')\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n"
     ]
    }
   ],
   "metadata": {
    "id": "o_grs6OGpfDJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10. Freezing the Graph"
   ],
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ],
   "outputs": [],
   "metadata": {
    "id": "n4olHB2npfDJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "0AjO93QDpfDJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(command)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{command}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## use export_inference_graph.py to export frozen graph for object counting api\r\n",
    "OBJECT_COUNTING_FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_inference_graph.py ')\r\n",
    "cmd = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_prefix={} --output_directory={}\".format(OBJECT_COUNTING_FREEZE_SCRIPT, files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\r\n",
    "print(cmd)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{cmd} "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 11. Conversion to TFJS"
   ],
   "metadata": {
    "id": "wTPmdqaXpfDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install tensorflowjs"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "0oxbVynHpfDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(command)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{command}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ],
   "outputs": [],
   "metadata": {
    "id": "o8_hm-itpfDK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 12. Conversion to TFLite"
   ],
   "metadata": {
    "id": "VtUw73FHpfDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ],
   "outputs": [],
   "metadata": {
    "id": "XviMtewLpfDK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "us86cjC4pfDL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(command)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{command}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ],
   "outputs": [],
   "metadata": {
    "id": "iJfYMbN6pfDL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(command)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!{command}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 13. Zip and Export Models "
   ],
   "metadata": {
    "id": "5NQqZRdA21Uc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ],
   "outputs": [],
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tf2.5': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "ac99008b9fbc31fa9df4b15f720b5f0aa36e81483f11ef5f2812b44abbc3deb3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}